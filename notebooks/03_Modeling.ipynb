{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: (3000, 2)\n",
      "라벨 분포:\n",
      "0    1000\n",
      "1    1000\n",
      "2    1000\n",
      "Name: label, dtype: int64\n",
      "감정 매핑: {0: '우울', 1: '불안', 2: '정상'}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "df = pd.read_csv('../data/processed/korean_sentiment_dataset.csv')\n",
    "print(f\"데이터 크기: {df.shape}\")\n",
    "print(f\"라벨 분포:\\n{df['label'].value_counts().sort_index()}\")\n",
    "\n",
    "emotion_map = {0: '우울', 1: '불안', 2: '정상'}\n",
    "print(\"감정 매핑:\", emotion_map)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련: 2400, 테스트: 600\n"
     ]
    }
   ],
   "source": [
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"훈련: {len(X_train)}, 테스트: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 특성 수: 1217\n",
      "훈련 벡터 크기: (2400, 1217)\n",
      "테스트 벡터 크기: (600, 1217)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=3000,\n",
    "    ngram_range=(1,2),\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF 특성 수: {X_train_tfidf.shape[1]}\")\n",
    "print(f\"훈련 벡터 크기: {X_train_tfidf.shape}\")\n",
    "print(f\"테스트 벡터 크기: {X_test_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 정확도: 1.0000\n",
      "SVM 정확도: 1.0000\n",
      "SVM 정확도: 1.0000\n",
      "Random Forest 정확도: 1.0000\n",
      "Random Forest 정확도: 1.0000\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Logistic Regression' : LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'SVM' : SVC(random_state=42, kernel='linear'),\n",
    "    'Random Forest' : RandomForestClassifier(random_state=42,n_estimators=100)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = {\n",
    "        'model' : model,\n",
    "        'accuracy' : accuracy,\n",
    "        'predictions' : y_pred,\n",
    "    }\n",
    "    print(f\"{name} 정확도: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🥇 최고 성능 모델: Logistic Regression\n",
      "정확도: 1.0000\n",
      "==================================================\n",
      "\n",
      "Logistic Regression 상세 성능:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          우울       1.00      1.00      1.00       200\n",
      "          불안       1.00      1.00      1.00       200\n",
      "          정상       1.00      1.00      1.00       200\n",
      "\n",
      "    accuracy                           1.00       600\n",
      "   macro avg       1.00      1.00      1.00       600\n",
      "weighted avg       1.00      1.00      1.00       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])\n",
    "best_model = results[best_model_name]['model']\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "print(f\"🥇 최고 성능 모델: {best_model_name}\")\n",
    "print(f\"정확도: {results[best_model_name]['accuracy']:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 분류 리포트\n",
    "print(f\"\\n{best_model_name} 상세 성능:\")\n",
    "emotions = ['우울', '불안', '정상']\n",
    "print(classification_report(y_test, best_predictions, target_names=emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "@st.cache_resource\n",
    "def load_models():\n",
    "    try:\n",
    "        # 상대 경로를 절대 경로로 변경\n",
    "        model = joblib.load('../models/best_model.pkl')  \n",
    "        tfidf = joblib.load('../models/tfidf_vectorizer.pkl') \n",
    "        return model, tfidf\n",
    "    except Exception as e:\n",
    "        st.error(f\"모델 로드 실패: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def predict_emotion(text):\n",
    "    cleaned = re.sub(r'[^가-힣a-zA-Z0-9\\s]', ' ', text)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "    \n",
    "    text_tfidf = tfidf.transform([cleaned])\n",
    "    prediction = best_model.predict(text_tfidf)[0]\n",
    "    \n",
    "    return emotion_map[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 모델 테스트:\n",
      "==================================================\n",
      "문장: '오늘 정말 우울하고 슬퍼요'\n",
      "예측: 정상\n",
      "\n",
      "문장: '시험이 너무 걱정되고 불안해요'\n",
      "예측: 불안\n",
      "\n",
      "문장: '날씨가 좋아서 정말 기분이 좋아요'\n",
      "예측: 정상\n",
      "\n",
      "문장: '아무것도 하기 싫고 의욕이 없어요'\n",
      "예측: 우울\n",
      "\n",
      "문장: '혹시 실수할까봐 계속 걱정돼요'\n",
      "예측: 불안\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트\n",
    "test_sentences = [\n",
    "    \"오늘 정말 우울하고 슬퍼요\",\n",
    "    \"시험이 너무 걱정되고 불안해요\", \n",
    "    \"날씨가 좋아서 정말 기분이 좋아요\",\n",
    "    \"아무것도 하기 싫고 의욕이 없어요\",\n",
    "    \"혹시 실수할까봐 계속 걱정돼요\"\n",
    "]\n",
    "\n",
    "print(\"🧪 모델 테스트:\")\n",
    "print(\"=\"*50)\n",
    "for sentence in test_sentences:\n",
    "    emotion = predict_emotion(sentence)\n",
    "    print(f\"문장: '{sentence}'\")\n",
    "    print(f\"예측: {emotion}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 모델 파일 저장 성공!\n"
     ]
    }
   ],
   "source": [
    "# 저장 확인\n",
    "import os\n",
    "if os.path.exists('../models/best_model.pkl'):\n",
    "    print(\"🎉 모델 파일 저장 성공!\")\n",
    "else:\n",
    "    print(\"❌ 모델 파일 저장 실패!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 새로운 모델 저장 중...\n",
      "==================================================\n",
      "✅ 모델 저장 완료!\n",
      "📊 모델: Logistic Regression\n",
      "🎯 정확도: 1.0000\n",
      "📁 저장 위치:\n",
      "  - ../models/best_model.pkl\n",
      "  - ../models/tfidf_vectorizer.pkl\n",
      "\n",
      "🎉 이제 웹앱에서 새로운 모델을 사용할 수 있습니다!\n",
      "✅ 모델 저장 완료!\n",
      "📊 모델: Logistic Regression\n",
      "🎯 정확도: 1.0000\n",
      "📁 저장 위치:\n",
      "  - ../models/best_model.pkl\n",
      "  - ../models/tfidf_vectorizer.pkl\n",
      "\n",
      "🎉 이제 웹앱에서 새로운 모델을 사용할 수 있습니다!\n"
     ]
    }
   ],
   "source": [
    "# 💾 새로운 모델 저장\n",
    "print(\"💾 새로운 모델 저장 중...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 모델과 TF-IDF 벡터라이저 저장\n",
    "joblib.dump(best_model, '../models/best_model.pkl')\n",
    "joblib.dump(tfidf, '../models/tfidf_vectorizer.pkl')\n",
    "\n",
    "print(f\"✅ 모델 저장 완료!\")\n",
    "print(f\"📊 모델: {best_model_name}\")\n",
    "print(f\"🎯 정확도: {results[best_model_name]['accuracy']:.4f}\")\n",
    "print(f\"📁 저장 위치:\")\n",
    "print(f\"  - ../models/best_model.pkl\")\n",
    "print(f\"  - ../models/tfidf_vectorizer.pkl\")\n",
    "print(\"\\n🎉 이제 웹앱에서 새로운 모델을 사용할 수 있습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 모델 성능 재확인:\n",
      "최고 모델: Logistic Regression\n",
      "정확도: 1.0000\n",
      "\n",
      "예측 결과 분포:\n",
      "0    200\n",
      "1    200\n",
      "2    200\n",
      "dtype: int64\n",
      "\n",
      "실제 라벨 분포:\n",
      "0    200\n",
      "1    200\n",
      "2    200\n",
      "Name: label, dtype: int64\n",
      "\n",
      "예측 비율:\n",
      "우울: 200개 (33.3%)\n",
      "불안: 200개 (33.3%)\n",
      "정상: 200개 (33.3%)\n"
     ]
    }
   ],
   "source": [
    "# 🔍 모델 성능 진단\n",
    "print(\"🔍 모델 성능 재확인:\")\n",
    "print(f\"최고 모델: {best_model_name}\")\n",
    "print(f\"정확도: {results[best_model_name]['accuracy']:.4f}\")\n",
    "\n",
    "# 예측 결과 분포 확인\n",
    "print(\"\\n예측 결과 분포:\")\n",
    "pred_counts = pd.Series(best_predictions).value_counts().sort_index()\n",
    "print(pred_counts)\n",
    "\n",
    "print(\"\\n실제 라벨 분포:\")\n",
    "true_counts = pd.Series(y_test).value_counts().sort_index()\n",
    "print(true_counts)\n",
    "\n",
    "# 예측 비율 확인\n",
    "print(\"\\n예측 비율:\")\n",
    "for i in range(3):\n",
    "    emotion = ['우울', '불안', '정상'][i]\n",
    "    if i in pred_counts.index:\n",
    "        ratio = pred_counts[i] / len(y_test) * 100\n",
    "        print(f\"{emotion}: {pred_counts[i]}개 ({ratio:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"{emotion}: 0개 (0.0%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 웹앱 전처리 함수 테스트\n",
      "==================================================\n",
      "\n",
      "📝 테스트 결과:\n",
      "원본: '우울해요'\n",
      "정리: '우울해요'\n",
      "처리: '우울해요'\n",
      "예측: 정상\n",
      "확률: ['0.322', '0.326', '0.352']\n",
      "------------------------------\n",
      "원본: '우울하다'\n",
      "정리: '우울하다'\n",
      "처리: '우울하다'\n",
      "예측: 정상\n",
      "확률: ['0.322', '0.326', '0.352']\n",
      "------------------------------\n",
      "원본: '오늘 정말 우울해요'\n",
      "정리: '오늘 정말 우울해요'\n",
      "처리: '오늘 정말 우울해요'\n",
      "예측: 정상\n",
      "확률: ['0.091', '0.093', '0.816']\n",
      "------------------------------\n",
      "원본: '우울하고 슬퍼요'\n",
      "정리: '우울하고 슬퍼요'\n",
      "처리: '우울하고 슬퍼요'\n",
      "예측: 정상\n",
      "확률: ['0.322', '0.326', '0.352']\n",
      "------------------------------\n",
      "원본: '불안해요'\n",
      "정리: '불안해요'\n",
      "처리: '불안해요'\n",
      "예측: 불안\n",
      "확률: ['0.123', '0.730', '0.147']\n",
      "------------------------------\n",
      "원본: '걱정돼요'\n",
      "정리: '걱정돼요'\n",
      "처리: '걱정돼요'\n",
      "예측: 정상\n",
      "확률: ['0.322', '0.326', '0.352']\n",
      "------------------------------\n",
      "원본: '기분이 좋아요'\n",
      "정리: '기분이 좋아요'\n",
      "처리: '기분이 좋아요'\n",
      "예측: 정상\n",
      "확률: ['0.044', '0.045', '0.911']\n",
      "------------------------------\n",
      "원본: '행복해요'\n",
      "정리: '행복해요'\n",
      "처리: '행복해요'\n",
      "예측: 정상\n",
      "확률: ['0.322', '0.326', '0.352']\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 🔍 웹앱과 동일한 전처리로 실제 테스트\n",
    "print(\"🧪 웹앱 전처리 함수 테스트\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def clean_text_webapp(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', str(text))\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "STOPWORDS = ['이', '그', '저', '것', '의', '가', '을', '를', '에', '에서', '로', '으로', '와', '과', '은', '는', '이다', '하다']\n",
    "\n",
    "def remove_stopwords_webapp(text):\n",
    "    words = text.split()\n",
    "    return ' '.join([word for word in words if word not in STOPWORDS and len(word) > 1])\n",
    "\n",
    "def predict_webapp_style(text):\n",
    "    # 웹앱과 동일한 전처리\n",
    "    cleaned = clean_text_webapp(text)\n",
    "    processed = remove_stopwords_webapp(cleaned)\n",
    "    \n",
    "    print(f\"원본: '{text}'\")\n",
    "    print(f\"정리: '{cleaned}'\")\n",
    "    print(f\"처리: '{processed}'\")\n",
    "    \n",
    "    if not processed.strip():\n",
    "        print(\"⚠️ 전처리 후 빈 문자열!\")\n",
    "        return None, None\n",
    "    \n",
    "    # 벡터화 및 예측\n",
    "    text_tfidf = tfidf.transform([processed])\n",
    "    prediction = best_model.predict(text_tfidf)[0]\n",
    "    probability = best_model.predict_proba(text_tfidf)[0]\n",
    "    \n",
    "    emotion_map = {0: '우울', 1: '불안', 2: '정상'}\n",
    "    \n",
    "    print(f\"예측: {emotion_map[prediction]}\")\n",
    "    print(f\"확률: {[f'{p:.3f}' for p in probability]}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    return emotion_map[prediction], probability\n",
    "\n",
    "# 테스트 문장들\n",
    "test_sentences = [\n",
    "    \"우울해요\",\n",
    "    \"우울하다\",\n",
    "    \"오늘 정말 우울해요\",\n",
    "    \"우울하고 슬퍼요\",\n",
    "    \"불안해요\",\n",
    "    \"걱정돼요\",\n",
    "    \"기분이 좋아요\",\n",
    "    \"행복해요\"\n",
    "]\n",
    "\n",
    "print(\"\\n📝 테스트 결과:\")\n",
    "for sentence in test_sentences:\n",
    "    predict_webapp_style(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 원본 데이터 '우울' 관련 분석\n",
      "==================================================\n",
      "'우울' 단어 포함 문장 수: 0\n",
      "\n",
      "각 라벨별 '우울' 포함 문장:\n",
      "우울: 0개\n",
      "\n",
      "불안: 0개\n",
      "\n",
      "정상: 0개\n",
      "\n",
      "\n",
      "'불안' 단어 포함 문장 수: 319\n",
      "\n",
      "각 라벨별 '불안' 포함 문장:\n",
      "우울: 0개\n",
      "불안: 319개\n",
      "정상: 0개\n",
      "'우울' 단어 포함 문장 수: 0\n",
      "\n",
      "각 라벨별 '우울' 포함 문장:\n",
      "우울: 0개\n",
      "\n",
      "불안: 0개\n",
      "\n",
      "정상: 0개\n",
      "\n",
      "\n",
      "'불안' 단어 포함 문장 수: 319\n",
      "\n",
      "각 라벨별 '불안' 포함 문장:\n",
      "우울: 0개\n",
      "불안: 319개\n",
      "정상: 0개\n"
     ]
    }
   ],
   "source": [
    "# 🔍 원본 데이터에서 '우울' 관련 단어 분석\n",
    "print(\"📊 원본 데이터 '우울' 관련 분석\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 원본 데이터 로드\n",
    "raw_df = pd.read_csv('../data/raw/korean_sentiment_dataset.csv')\n",
    "\n",
    "# '우울' 단어가 포함된 문장들 찾기\n",
    "depression_texts = raw_df[raw_df['text'].str.contains('우울', na=False)]\n",
    "print(f\"'우울' 단어 포함 문장 수: {len(depression_texts)}\")\n",
    "\n",
    "print(\"\\n각 라벨별 '우울' 포함 문장:\")\n",
    "for label in [0, 1, 2]:\n",
    "    emotion = ['우울', '불안', '정상'][label]\n",
    "    count = len(depression_texts[depression_texts['label'] == label])\n",
    "    print(f\"{emotion}: {count}개\")\n",
    "    \n",
    "    # 샘플 출력\n",
    "    samples = depression_texts[depression_texts['label'] == label]['text'].head(3).tolist()\n",
    "    for i, text in enumerate(samples, 1):\n",
    "        print(f\"  {i}. {text}\")\n",
    "    print()\n",
    "\n",
    "# '불안' 단어도 비교해보자\n",
    "anxiety_texts = raw_df[raw_df['text'].str.contains('불안', na=False)]\n",
    "print(f\"\\n'불안' 단어 포함 문장 수: {len(anxiety_texts)}\")\n",
    "\n",
    "print(\"\\n각 라벨별 '불안' 포함 문장:\")\n",
    "for label in [0, 1, 2]:\n",
    "    emotion = ['우울', '불안', '정상'][label]\n",
    "    count = len(anxiety_texts[anxiety_texts['label'] == label])\n",
    "    print(f\"{emotion}: {count}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 각 감정별 실제 문장 샘플\n",
      "============================================================\n",
      "\n",
      "🎭 우울 라벨 샘플 (10개):\n",
      "   1. 사실은 하루하루가 너무 힘들어요입니다.\n",
      "   2. 가끔은 마음이 자꾸 가라앉고 어두워요 너무였어요.\n",
      "   3. 어느 순간부터 아무 이유 없이 눈물이 나요 너무였어요.\n",
      "   4. 어느 순간부터 기운이 하나도 없고 아무것도 하기 싫어요입니다.\n",
      "   5. 이상하게도 모든 게 다 나 때문인 것 같아요 괜히했어요.\n",
      "   6. 이상하게도 일어나기가 너무 힘들어요 항상요.\n",
      "   7. 요즘 따라 일어나기가 너무 힘들어요 너무했어요.\n",
      "   8. 그냥 기운이 하나도 없고 아무것도 하기 싫어요 정말했어요.\n",
      "   9. 요즘 따라 요즘 사는 게 무의미하게 느껴져요 정말하네요.\n",
      "  10. 솔직히 요즘 사는 게 무의미하게 느껴져요 별 이유 없이.\n",
      "\n",
      "우울 라벨에서 자주 나오는 단어들:\n",
      "    너무: 299회\n",
      "    요즘: 234회\n",
      "    없고: 197회\n",
      "    이유: 194회\n",
      "    힘들어요: 160회\n",
      "    어느: 120회\n",
      "    순간부터: 120회\n",
      "    그냥: 118회\n",
      "------------------------------------------------------------\n",
      "\n",
      "🎭 불안 라벨 샘플 (10개):\n",
      "   1. 그냥 사람들 앞에 서는 게 너무 무서워요 괜히입니다.\n",
      "   2. 솔직히 계속 가슴이 답답하고 조마조마해요입니다.\n",
      "   3. 작은 일에도 깜짝깜짝 놀라요 정말했어요.\n",
      "   4. 솔직히 사람들 앞에 서는 게 너무 무서워요 자꾸.\n",
      "   5. 어느 순간부터 불안해서 잠을 잘 수가 없어요 항상였어요.\n",
      "   6. 이상하게도 작은 일에도 깜짝깜짝 놀라요 너무하네요.\n",
      "   7. 어느 순간부터 사람들 앞에 서는 게 너무 무서워요 매일입니다.\n",
      "   8. 솔직히 작은 일에도 깜짝깜짝 놀라요 정말요.\n",
      "   9. 그냥 불안해서 잠을 잘 수가 없어요 자꾸요.\n",
      "  10. 이상하게도 내일 시험 생각만 해도 가슴이 뛰어요 매일.\n",
      "\n",
      "불안 라벨에서 자주 나오는 단어들:\n",
      "    가슴이: 216회\n",
      "    자꾸: 212회\n",
      "    요즘: 138회\n",
      "    따라: 122회\n",
      "    솔직히: 120회\n",
      "    사실은: 120회\n",
      "    나만: 117회\n",
      "    뒤처질까: 117회\n",
      "------------------------------------------------------------\n",
      "\n",
      "🎭 정상 라벨 샘플 (10개):\n",
      "   1. 이상하게도 좋아하는 노래를 들으니 기분이 좋아졌어요 별 이유 없이싶어요.\n",
      "   2. 솔직히 커피 한 잔 마시면서 여유를 즐겼어요하네요.\n",
      "   3. 솔직히 밥이 너무 맛있게 느껴졌어요 정말요.\n",
      "   4. 문득 커피 한 잔 마시면서 여유를 즐겼어요 매일네요.\n",
      "   5. 솔직히 커피 한 잔 마시면서 여유를 즐겼어요 너무요.\n",
      "   6. 그냥 밥이 너무 맛있게 느껴졌어요.\n",
      "   7. 가족과 함께 보낸 시간이 소중했어요 별 이유 없이요.\n",
      "   8. 문득 가족과 함께 보낸 시간이 소중했어요 항상싶어요.\n",
      "   9. 문득 책 읽으면서 조용한 시간을 보냈어요 자꾸싶어요.\n",
      "  10. 문득 주말에 맛집 탐방하러 다녀왔어요 요즘입니다.\n",
      "\n",
      "정상 라벨에서 자주 나오는 단어들:\n",
      "    기분이: 186회\n",
      "    좋아졌어요: 171회\n",
      "    그냥: 127회\n",
      "    솔직히: 126회\n",
      "    요즘: 124회\n",
      "    정말: 118회\n",
      "    어느: 117회\n",
      "    순간부터: 117회\n",
      "    따라: 116회\n",
      "    너무: 115회\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 🔍 각 감정별 실제 데이터 내용 분석\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "print(\"📝 각 감정별 실제 문장 샘플\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "raw_df = pd.read_csv('../data/raw/korean_sentiment_dataset.csv')\n",
    "\n",
    "for label in [0, 1, 2]:\n",
    "    emotion = ['우울', '불안', '정상'][label]\n",
    "    emotion_data = raw_df[raw_df['label'] == label]\n",
    "    \n",
    "    print(f\"\\n🎭 {emotion} 라벨 샘플 (10개):\")\n",
    "    samples = emotion_data['text'].head(10).tolist()\n",
    "    for i, text in enumerate(samples, 1):\n",
    "        print(f\"  {i:2d}. {text}\")\n",
    "    \n",
    "    print(f\"\\n{emotion} 라벨에서 자주 나오는 단어들:\")\n",
    "    all_text = ' '.join(emotion_data['text'].astype(str))\n",
    "    # 간단한 단어 빈도 분석\n",
    "    words = re.findall(r'[가-힣]+', all_text)\n",
    "    word_freq = Counter(words)\n",
    "    top_words = word_freq.most_common(10)\n",
    "    for word, freq in top_words:\n",
    "        if len(word) > 1:  # 한 글자 단어 제외\n",
    "            print(f\"    {word}: {freq}회\")\n",
    "    \n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 새로운 모델 실전 테스트\n",
      "============================================================\n",
      "📝 테스트 결과:\n",
      "입력: '밥이 맛있다'\n",
      "처리: '밥이 맛있다'\n",
      "예측: 정상 (0.824)\n",
      "전체 확률: 우울(0.081) 불안(0.095) 정상(0.824)\n",
      "--------------------------------------------------\n",
      "입력: '날이 화창해요'\n",
      "처리: '날이 화창해요'\n",
      "예측: 정상 (0.352)\n",
      "전체 확률: 우울(0.322) 불안(0.326) 정상(0.352)\n",
      "--------------------------------------------------\n",
      "입력: '오늘 정말 우울해요'\n",
      "처리: '오늘 정말 우울해요'\n",
      "예측: 정상 (0.816)\n",
      "전체 확률: 우울(0.091) 불안(0.093) 정상(0.816)\n",
      "--------------------------------------------------\n",
      "입력: '너무 불안하고 걱정돼요'\n",
      "처리: '너무 불안하고 걱정돼요'\n",
      "예측: 우울 (0.833)\n",
      "전체 확률: 우울(0.833) 불안(0.073) 정상(0.094)\n",
      "--------------------------------------------------\n",
      "입력: '기분이 정말 좋아요'\n",
      "처리: '기분이 정말 좋아요'\n",
      "예측: 정상 (0.930)\n",
      "전체 확률: 우울(0.034) 불안(0.035) 정상(0.930)\n",
      "--------------------------------------------------\n",
      "입력: '아무것도 하기 싫어요'\n",
      "처리: '아무것도 하기 싫어요'\n",
      "예측: 우울 (0.877)\n",
      "전체 확률: 우울(0.877) 불안(0.060) 정상(0.062)\n",
      "--------------------------------------------------\n",
      "입력: '시험 때문에 스트레스 받아요'\n",
      "처리: '시험 때문에 스트레스 받아요'\n",
      "예측: 불안 (0.666)\n",
      "전체 확률: 우울(0.155) 불안(0.666) 정상(0.180)\n",
      "--------------------------------------------------\n",
      "입력: '친구들과 놀러가서 즐거웠어요'\n",
      "처리: '친구들과 놀러가서 즐거웠어요'\n",
      "예측: 정상 (0.352)\n",
      "전체 확률: 우울(0.322) 불안(0.326) 정상(0.352)\n",
      "--------------------------------------------------\n",
      "입력: '그냥 그래요'\n",
      "처리: '그냥 그래요'\n",
      "예측: 정상 (0.356)\n",
      "전체 확률: 우울(0.343) 불안(0.300) 정상(0.356)\n",
      "--------------------------------------------------\n",
      "입력: '별로 안 좋아요'\n",
      "처리: '별로 좋아요'\n",
      "예측: 정상 (0.685)\n",
      "전체 확률: 우울(0.156) 불안(0.159) 정상(0.685)\n",
      "--------------------------------------------------\n",
      "입력: '괜찮은 것 같아요'\n",
      "처리: '괜찮은 같아요'\n",
      "예측: 우울 (0.769)\n",
      "전체 확률: 우울(0.769) 불안(0.112) 정상(0.119)\n",
      "--------------------------------------------------\n",
      "입력: '기분이 정말 좋아요'\n",
      "처리: '기분이 정말 좋아요'\n",
      "예측: 정상 (0.930)\n",
      "전체 확률: 우울(0.034) 불안(0.035) 정상(0.930)\n",
      "--------------------------------------------------\n",
      "입력: '아무것도 하기 싫어요'\n",
      "처리: '아무것도 하기 싫어요'\n",
      "예측: 우울 (0.877)\n",
      "전체 확률: 우울(0.877) 불안(0.060) 정상(0.062)\n",
      "--------------------------------------------------\n",
      "입력: '시험 때문에 스트레스 받아요'\n",
      "처리: '시험 때문에 스트레스 받아요'\n",
      "예측: 불안 (0.666)\n",
      "전체 확률: 우울(0.155) 불안(0.666) 정상(0.180)\n",
      "--------------------------------------------------\n",
      "입력: '친구들과 놀러가서 즐거웠어요'\n",
      "처리: '친구들과 놀러가서 즐거웠어요'\n",
      "예측: 정상 (0.352)\n",
      "전체 확률: 우울(0.322) 불안(0.326) 정상(0.352)\n",
      "--------------------------------------------------\n",
      "입력: '그냥 그래요'\n",
      "처리: '그냥 그래요'\n",
      "예측: 정상 (0.356)\n",
      "전체 확률: 우울(0.343) 불안(0.300) 정상(0.356)\n",
      "--------------------------------------------------\n",
      "입력: '별로 안 좋아요'\n",
      "처리: '별로 좋아요'\n",
      "예측: 정상 (0.685)\n",
      "전체 확률: 우울(0.156) 불안(0.159) 정상(0.685)\n",
      "--------------------------------------------------\n",
      "입력: '괜찮은 것 같아요'\n",
      "처리: '괜찮은 같아요'\n",
      "예측: 우울 (0.769)\n",
      "전체 확률: 우울(0.769) 불안(0.112) 정상(0.119)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 🧪 새로운 모델 실전 테스트 - 문제 문장들 포함\n",
    "print(\"🧪 새로운 모델 실전 테스트\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def test_new_model(text):\n",
    "    # 전처리 (웹앱과 동일)\n",
    "    cleaned = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', str(text))\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "    \n",
    "    # 불용어 제거\n",
    "    STOPWORDS = ['이', '그', '저', '것', '의', '가', '을', '를', '에', '에서', '로', '으로', '와', '과', '은', '는', '이다', '하다']\n",
    "    words = cleaned.split()\n",
    "    processed = ' '.join([word for word in words if word not in STOPWORDS and len(word) > 1])\n",
    "    \n",
    "    if not processed.strip():\n",
    "        processed = cleaned  # 불용어 제거 후 빈 문자열이면 원본 사용\n",
    "    \n",
    "    # 예측\n",
    "    text_tfidf = tfidf.transform([processed])\n",
    "    prediction = best_model.predict(text_tfidf)[0]\n",
    "    probability = best_model.predict_proba(text_tfidf)[0]\n",
    "    \n",
    "    emotion_map = {0: '우울', 1: '불안', 2: '정상'}\n",
    "    \n",
    "    print(f\"입력: '{text}'\")\n",
    "    print(f\"처리: '{processed}'\")\n",
    "    print(f\"예측: {emotion_map[prediction]} ({probability[prediction]:.3f})\")\n",
    "    print(f\"전체 확률: 우울({probability[0]:.3f}) 불안({probability[1]:.3f}) 정상({probability[2]:.3f})\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    return emotion_map[prediction]\n",
    "\n",
    "# 문제가 있던 문장들과 다양한 테스트 문장들\n",
    "test_sentences = [\n",
    "    # 사용자가 문제 제기한 문장\n",
    "    \"밥이 맛있다\",\n",
    "    \"날이 화창해요\",\n",
    "    \n",
    "    # 명확한 감정 표현들\n",
    "    \"오늘 정말 우울해요\",\n",
    "    \"너무 불안하고 걱정돼요\",\n",
    "    \"기분이 정말 좋아요\",\n",
    "    \n",
    "    # 간접적 표현들\n",
    "    \"아무것도 하기 싫어요\",\n",
    "    \"시험 때문에 스트레스 받아요\",\n",
    "    \"친구들과 놀러가서 즐거웠어요\",\n",
    "    \n",
    "    # 애매한 표현들\n",
    "    \"그냥 그래요\",\n",
    "    \"별로 안 좋아요\",\n",
    "    \"괜찮은 것 같아요\"\n",
    "]\n",
    "\n",
    "print(\"📝 테스트 결과:\")\n",
    "for sentence in test_sentences:\n",
    "    test_new_model(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
