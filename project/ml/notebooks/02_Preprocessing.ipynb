{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/korean_sentiment_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = re.sub(r'[^ê°€-í£a-zA-Z0-9\\s]','',str(text))\n",
    "    text = re.sub(r'\\s+',' ',text).strip()\n",
    "    return text\n",
    "\n",
    "STOPWORDS = ['ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ì˜', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ë¡œ', 'ìœ¼ë¡œ', 'ì™€', 'ê³¼', 'ì€', 'ëŠ”', 'ì´ë‹¤', 'í•˜ë‹¤']\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    return ' '.join([word for word in words if word not in STOPWORDS and len(word) > 1])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: (3000, 3)\n",
      "\n",
      "ì „ì²˜ë¦¬ ê²°ê³¼:\n",
      "ì›ë³¸: ê·¸ëƒ¥ ì‚¬ëŒë“¤ ì•ì— ì„œëŠ” ê²Œ ë„ˆë¬´ ë¬´ì„œì›Œìš” ê´œíˆì…ë‹ˆë‹¤.\n",
      "ì²˜ë¦¬: ê·¸ëƒ¥ ì‚¬ëŒë“¤ ì•ì— ì„œëŠ” ë„ˆë¬´ ë¬´ì„œì›Œìš” ê´œíˆì…ë‹ˆë‹¤\n",
      "\n",
      "ì›ë³¸: ì†”ì§íˆ ê³„ì† ê°€ìŠ´ì´ ë‹µë‹µí•˜ê³  ì¡°ë§ˆì¡°ë§ˆí•´ìš”ì…ë‹ˆë‹¤.\n",
      "ì²˜ë¦¬: ì†”ì§íˆ ê³„ì† ê°€ìŠ´ì´ ë‹µë‹µí•˜ê³  ì¡°ë§ˆì¡°ë§ˆí•´ìš”ì…ë‹ˆë‹¤\n",
      "\n",
      "ì›ë³¸: ì‘ì€ ì¼ì—ë„ ê¹œì§ê¹œì§ ë†€ë¼ìš” ì •ë§í–ˆì–´ìš”.\n",
      "ì²˜ë¦¬: ì‘ì€ ì¼ì—ë„ ê¹œì§ê¹œì§ ë†€ë¼ìš” ì •ë§í–ˆì–´ìš”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['processed_text'] = df['text'].apply(clean_text).apply(remove_stopwords)\n",
    "df[df['processed_text'].str.len() > 0].reset_index(drop=True)\n",
    "print(f\"ì „ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: {df.shape}\")\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸ (3ê°œë§Œ)\n",
    "print(\"\\nì „ì²˜ë¦¬ ê²°ê³¼:\")\n",
    "for i in range(3):\n",
    "    print(f\"ì›ë³¸: {df.iloc[i]['text']}\")\n",
    "    print(f\"ì²˜ë¦¬: {df.iloc[i]['processed_text']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: (3000, 2)\n"
     ]
    }
   ],
   "source": [
    "final_df = df[['processed_text', 'label']].copy()\n",
    "final_df.rename(columns={'processed_text' : 'text'}, inplace=True)\n",
    "\n",
    "final_df.to_csv('../data/processed/korean_sentiment_dataset.csv', index=False, encoding='utf-8')\n",
    "print(f\"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {final_df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
